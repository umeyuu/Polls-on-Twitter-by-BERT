{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertJapaneseTokenizer\n",
    "from torch.utils.data import SequentialSampler\n",
    "from src.dataset import My_DATASET\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attentionの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "model_path = 'save_model/best_model.pth'\n",
    "data_path = 'DATA/serched_tweet/イーロンマスク.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/umeda-yuusuke469/Polls-on-Twitter-by-BERT/env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# モデルを読み込む\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, # 日本語Pre trainedモデルの指定\n",
    "        num_labels = 3, # ラベル数\n",
    "        output_attentions = False, # アテンションベクトルを出力するか\n",
    "        output_hidden_states = False, # 隠れ層を出力するか\n",
    "    )\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n",
    "df = pd.read_csv(data_path)\n",
    "df.columns = ['tweet']\n",
    "tweets = df.tweet.values.tolist()\n",
    "# データローダー\n",
    "dataset = My_DATASET(MODEL_NAME, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(word, attn):\n",
    "    html_color = '#%02X%02X%02X' % (255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
    "    return f'<span style=\"background-color: {html_color}\">{word}</span>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'マジでTwitterどうした？？\\nイーロンマスク、あんた色々とTwitterに介入してきた割には辞めるの早すぎやろ\\n\\n【CEOを引き受ける愚かな人が見つかればすぐに辞任する］\\nマジでこいつなんなん？？\\n茶番劇にしか見えないんだけど、規模が大きすぎてて仮に冗談だとしても全く笑えんし、単純に不快だわ！'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 12\n",
    "input_ids, input_mask = dataset[ind]\n",
    "output = model(input_ids.unsqueeze(0),\n",
    "            token_type_ids=None, \n",
    "            attention_mask=input_mask.unsqueeze(0),\n",
    "            output_attentions=True)\n",
    "attention_weight = output.attentions[-1]\n",
    "# 文章の長さ分のzero tensorを宣言\n",
    "seq_len = attention_weight.size()[2]\n",
    "all_attens = torch.zeros(seq_len)\n",
    "\n",
    "for i in range(12):\n",
    "    all_attens += attention_weight[0, i, 0, :]\n",
    "    \n",
    "html = ''\n",
    "for ids, attn in zip(input_ids, all_attens):\n",
    "    word = tokenizer.convert_ids_to_tokens([ids.numpy().tolist()])[0]\n",
    "    if word == \"[SEP]\":\n",
    "        break\n",
    "    html += highlight(word, attn)\n",
    "    # print(word, attn)\n",
    "html += \"<br><br>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.9128,  2.6702,  0.3474]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: #FF6464\">[CLS]</span><span style=\"background-color: #FF6161\">マジ</span><span style=\"background-color: #FFD0D0\">で</span><span style=\"background-color: #FFE9E9\">Twitter</span><span style=\"background-color: #FFF0F0\">どう</span><span style=\"background-color: #FFF9F9\">し</span><span style=\"background-color: #FFF6F6\">た</span><span style=\"background-color: #FFF6F6\">?</span><span style=\"background-color: #FFF2F2\">##?</span><span style=\"background-color: #FFD2D2\">イー</span><span style=\"background-color: #FFE9E9\">##ロン</span><span style=\"background-color: #FFCCCC\">##マス</span><span style=\"background-color: #FFB0B0\">##ク</span><span style=\"background-color: #FFC8C8\">、</span><span style=\"background-color: #FFEEEE\">あん</span><span style=\"background-color: #FFF4F4\">##た</span><span style=\"background-color: #FFF9F9\">色々</span><span style=\"background-color: #FFFCFC\">と</span><span style=\"background-color: #FFF9F9\">Twitter</span><span style=\"background-color: #FFF9F9\">に</span><span style=\"background-color: #FFA2A2\">介入</span><span style=\"background-color: #FFF3F3\">し</span><span style=\"background-color: #FFF7F7\">て</span><span style=\"background-color: #FFF7F7\">き</span><span style=\"background-color: #FFECEC\">た</span><span style=\"background-color: #FFF8F8\">割</span><span style=\"background-color: #FFFBFB\">に</span><span style=\"background-color: #FFF2F2\">は</span><span style=\"background-color: #FF6666\">辞め</span><span style=\"background-color: #FFF2F2\">##る</span><span style=\"background-color: #FFF2F2\">の</span><span style=\"background-color: #FFDDDD\">早</span><span style=\"background-color: #FFD8D8\">すぎ</span><span style=\"background-color: #FFA3A3\">やろ</span><span style=\"background-color: #FFC6C6\">【</span><span style=\"background-color: #FFF4F4\">CEO</span><span style=\"background-color: #FFEDED\">を</span><span style=\"background-color: #FF8585\">引き受ける</span><span style=\"background-color: #FFE6E6\">愚</span><span style=\"background-color: #FFEDED\">##か</span><span style=\"background-color: #FFF6F6\">な</span><span style=\"background-color: #FFE5E5\">人</span><span style=\"background-color: #FFF9F9\">が</span><span style=\"background-color: #FFF4F4\">見つ</span><span style=\"background-color: #FFFEFE\">##かれ</span><span style=\"background-color: #FFFBFB\">ば</span><span style=\"background-color: #FFF7F7\">すぐ</span><span style=\"background-color: #FFFBFB\">に</span><span style=\"background-color: #FF9292\">辞任</span><span style=\"background-color: #FFDADA\">する</span><span style=\"background-color: #FFC1C1\">]</span><span style=\"background-color: #FF8080\">マジ</span><span style=\"background-color: #FFA7A7\">で</span><span style=\"background-color: #FFC2C2\">こい</span><span style=\"background-color: #FF9494\">##つ</span><span style=\"background-color: #FFEBEB\">な</span><span style=\"background-color: #FFF8F8\">ん</span><span style=\"background-color: #FFFAFA\">な</span><span style=\"background-color: #FFF1F1\">ん</span><span style=\"background-color: #FFCDCD\">?</span><span style=\"background-color: #FFD9D9\">##?</span><span style=\"background-color: #FFF5F5\">茶</span><span style=\"background-color: #FFF2F2\">##番</span><span style=\"background-color: #FFF0F0\">劇</span><span style=\"background-color: #FFF9F9\">に</span><span style=\"background-color: #FFFBFB\">しか</span><span style=\"background-color: #FFF7F7\">見え</span><span style=\"background-color: #FFFBFB\">ない</span><span style=\"background-color: #FFFDFD\">ん</span><span style=\"background-color: #FFFBFB\">だ</span><span style=\"background-color: #FFF0F0\">けど</span><span style=\"background-color: #FFBBBB\">、</span><span style=\"background-color: #FFAFAF\">規模</span><span style=\"background-color: #FFF7F7\">が</span><span style=\"background-color: #FFEBEB\">大き</span><span style=\"background-color: #FFEEEE\">すぎ</span><span style=\"background-color: #FFF5F5\">て</span><span style=\"background-color: #FFF5F5\">て</span><span style=\"background-color: #FFFCFC\">仮に</span><span style=\"background-color: #FFD6D6\">冗談</span><span style=\"background-color: #FFFDFD\">だ</span><span style=\"background-color: #FFFDFD\">として</span><span style=\"background-color: #FFFBFB\">も</span><span style=\"background-color: #FFFBFB\">全く</span><span style=\"background-color: #FFF5F5\">笑</span><span style=\"background-color: #FFFBFB\">##え</span><span style=\"background-color: #FFEDED\">ん</span><span style=\"background-color: #FFEBEB\">し</span><span style=\"background-color: #FFD8D8\">、</span><span style=\"background-color: #FFF4F4\">単純</span><span style=\"background-color: #FFFBFB\">に</span><span style=\"background-color: #FFD2D2\">不快</span><span style=\"background-color: #FFE8E8\">だ</span><span style=\"background-color: #FFC7C7\">わ</span><span style=\"background-color: #FF5A5A\">!</span><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fa68adc62e7031bae3ea93887c966b90b33c87a0f2a1bab09fad928a22685fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

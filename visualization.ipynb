{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertJapaneseTokenizer\n",
    "from torch.utils.data import SequentialSampler\n",
    "from src.dataset import My_DATASET\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attentionの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "model_path = 'save_model/best_model.pth'\n",
    "data_path = 'DATA/serched_tweet/イーロンマスク.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/umeda-yuusuke469/Polls-on-Twitter-by-BERT/env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# モデルを読み込む\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, # 日本語Pre trainedモデルの指定\n",
    "        num_labels = 3, # ラベル数\n",
    "        output_attentions = False, # アテンションベクトルを出力するか\n",
    "        output_hidden_states = False, # 隠れ層を出力するか\n",
    "    )\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n",
    "df = pd.read_csv(data_path)\n",
    "df.columns = ['tweet']\n",
    "tweets = df.tweet.values.tolist()\n",
    "# データローダー\n",
    "dataset = My_DATASET(MODEL_NAME, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(word, attn):\n",
    "    html_color = '#%02X%02X%02X' % (255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
    "    return f'<span style=\"background-color: {html_color}\">{word}</span>'\n",
    "\n",
    "def id2label(id):\n",
    "    if id == 0:\n",
    "        return 'positive'\n",
    "    elif id == 1:\n",
    "        return 'negative'\n",
    "    elif id == 2:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'イーロンマスクは旧経営陣と同類の独裁者ではあるけど、旧悪によって苦しめられた層にとっては旧悪を倒してくれた救世主だし、自分達自身には直接的な不利益はもたらしてはいない以上は良質な経営者。本質的には単に視界に入っていないから、手出ししていないだけだとしてもこの事実には変わりない。'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 85\n",
    "input_ids, input_mask = dataset[ind]\n",
    "output = model(input_ids.unsqueeze(0),\n",
    "            token_type_ids=None, \n",
    "            attention_mask=input_mask.unsqueeze(0),\n",
    "            output_attentions=True)\n",
    "attention_weight = output.attentions[-1]\n",
    "id = output.logits.argmax(dim=1).item()\n",
    "label = id2label(id)\n",
    "# 文章の長さ分のzero tensorを宣言\n",
    "seq_len = attention_weight.size()[2]\n",
    "all_attens = torch.zeros(seq_len)\n",
    "\n",
    "for i in range(12):\n",
    "    all_attens += attention_weight[0, i, 0, :]\n",
    "    \n",
    "html = f'<big>推論ラベル：{label}</big><br>'\n",
    "for ids, attn in zip(input_ids, all_attens):\n",
    "    word = tokenizer.convert_ids_to_tokens([ids.numpy().tolist()])[0]\n",
    "    if word == \"[SEP]\":\n",
    "        break\n",
    "    html += highlight(word, attn)\n",
    "    # print(word, attn)\n",
    "html += \"<br><br>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<big>推論ラベル：positive</big><br><span style=\"background-color: #FF8888\">[CLS]</span><span style=\"background-color: #FFF5F5\">イー</span><span style=\"background-color: #FFFBFB\">##ロン</span><span style=\"background-color: #FFF8F8\">##マス</span><span style=\"background-color: #FFE7E7\">##ク</span><span style=\"background-color: #FFA0A0\">は</span><span style=\"background-color: #FFF9F9\">旧</span><span style=\"background-color: #FFEFEF\">経営</span><span style=\"background-color: #FFF3F3\">陣</span><span style=\"background-color: #FFFAFA\">と</span><span style=\"background-color: #FFFAFA\">同</span><span style=\"background-color: #FFF4F4\">##類</span><span style=\"background-color: #FFF2F2\">の</span><span style=\"background-color: #FFB6B6\">独裁</span><span style=\"background-color: #FFB6B6\">者</span><span style=\"background-color: #FFDEDE\">で</span><span style=\"background-color: #FFFBFB\">は</span><span style=\"background-color: #FFDDDD\">ある</span><span style=\"background-color: #FFDBDB\">けど</span><span style=\"background-color: #FFDBDB\">、</span><span style=\"background-color: #FFF6F6\">旧</span><span style=\"background-color: #FFF7F7\">##悪</span><span style=\"background-color: #FFFCFC\">によって</span><span style=\"background-color: #FFFAFA\">苦しめ</span><span style=\"background-color: #FFFDFD\">られ</span><span style=\"background-color: #FFF4F4\">た</span><span style=\"background-color: #FFF7F7\">層</span><span style=\"background-color: #FFFCFC\">にとって</span><span style=\"background-color: #FFF8F8\">は</span><span style=\"background-color: #FFFAFA\">旧</span><span style=\"background-color: #FFFAFA\">##悪</span><span style=\"background-color: #FFF9F9\">を</span><span style=\"background-color: #FFDEDE\">倒し</span><span style=\"background-color: #FFF6F6\">て</span><span style=\"background-color: #FFE9E9\">くれ</span><span style=\"background-color: #FFC1C1\">た</span><span style=\"background-color: #FFD7D7\">救世</span><span style=\"background-color: #FFC9C9\">##主</span><span style=\"background-color: #FF9595\">だ</span><span style=\"background-color: #FFD3D3\">し</span><span style=\"background-color: #FF9E9E\">、</span><span style=\"background-color: #FFEFEF\">自分</span><span style=\"background-color: #FFF3F3\">達</span><span style=\"background-color: #FFFBFB\">自身</span><span style=\"background-color: #FFFDFD\">に</span><span style=\"background-color: #FFFCFC\">は</span><span style=\"background-color: #FFFBFB\">直接的</span><span style=\"background-color: #FFFEFE\">な</span><span style=\"background-color: #FFFBFB\">不利</span><span style=\"background-color: #FFFDFD\">##益</span><span style=\"background-color: #FFFEFE\">は</span><span style=\"background-color: #FFFCFC\">もたらし</span><span style=\"background-color: #FFFCFC\">て</span><span style=\"background-color: #FFFDFD\">は</span><span style=\"background-color: #FFF5F5\">い</span><span style=\"background-color: #FFF8F8\">ない</span><span style=\"background-color: #FFE2E2\">以上</span><span style=\"background-color: #FFC0C0\">は</span><span style=\"background-color: #FF3E3E\">良質</span><span style=\"background-color: #FFB9B9\">な</span><span style=\"background-color: #FF5F5F\">経営</span><span style=\"background-color: #FF-F-F\">者</span><span style=\"background-color: #FF-75-75\">。</span><span style=\"background-color: #FFCFCF\">本質</span><span style=\"background-color: #FFFDFD\">的</span><span style=\"background-color: #FFFBFB\">に</span><span style=\"background-color: #FFF8F8\">は</span><span style=\"background-color: #FFF2F2\">単に</span><span style=\"background-color: #FFEAEA\">視界</span><span style=\"background-color: #FFFCFC\">に</span><span style=\"background-color: #FFF5F5\">入っ</span><span style=\"background-color: #FFF6F6\">て</span><span style=\"background-color: #FFE8E8\">い</span><span style=\"background-color: #FFD3D3\">ない</span><span style=\"background-color: #FFCFCF\">から</span><span style=\"background-color: #FFDFDF\">、</span><span style=\"background-color: #FFFBFB\">手</span><span style=\"background-color: #FFFBFB\">##出し</span><span style=\"background-color: #FFFBFB\">し</span><span style=\"background-color: #FFFAFA\">て</span><span style=\"background-color: #FFF7F7\">い</span><span style=\"background-color: #FFFBFB\">ない</span><span style=\"background-color: #FFFBFB\">だけ</span><span style=\"background-color: #FFFCFC\">だ</span><span style=\"background-color: #FFFBFB\">として</span><span style=\"background-color: #FFF9F9\">も</span><span style=\"background-color: #FF9797\">この</span><span style=\"background-color: #FFB0B0\">事実</span><span style=\"background-color: #FFEEEE\">に</span><span style=\"background-color: #FFF1F1\">は</span><span style=\"background-color: #FFF1F1\">変わり</span><span style=\"background-color: #FFDDDD\">ない</span><span style=\"background-color: #FFB6B6\">。</span><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fa68adc62e7031bae3ea93887c966b90b33c87a0f2a1bab09fad928a22685fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
